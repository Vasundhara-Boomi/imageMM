{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Load the MS-COCO dataset\n",
    "dataset, info = tfds.load('coco/2017', with_info=True, as_supervised=True)\n",
    "\n",
    "# Split the dataset into training and validation (testing) sets\n",
    "train_data = dataset['train']\n",
    "val_data = dataset['validation']\n",
    "\n",
    "# Check the number of training and testing images\n",
    "train_size = info.splits['train'].num_examples\n",
    "val_size = info.splits['validation'].num_examples\n",
    "\n",
    "print(f'Training Images: {train_size}')\n",
    "print(f'Validation Images: {val_size}')\n",
    "\n",
    "def plot_images(dataset, num_images=5):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i, (image, label) in enumerate(dataset.take(num_images)):\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "plot_images(train_data)\n",
    "\n",
    "def augment_image(image):\n",
    "    image = tf.image.random_flip_left_right(image)  # Random horizontal flip\n",
    "    image = tf.image.random_flip_up_down(image)    # Random vertical flip\n",
    "    image = tf.image.random_contrast(image, lower=0.2, upper=0.5)  # Random contrast\n",
    "    image = tf.image.random_rotation(image, 0.2)   # Random rotation\n",
    "    return image\n",
    "\n",
    "# Apply augmentation on the dataset\n",
    "train_data = train_data.map(lambda image, label: (augment_image(image), label))\n",
    "val_data = val_data.map(lambda image, label: (augment_image(image), label))\n",
    "\n",
    "normalization_layer = layers.Rescaling(1.0 / 255)\n",
    "train_data = train_data.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_data = val_data.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "# Build a CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    layers.InputLayer(input_shape=(128, 128, 3)),  # Adjust size to 128x128 for simplicity\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_data.batch(32), validation_data=val_data.batch(32), epochs=10)\n",
    "\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "# Load the COCO dataset\n",
    "data_dir = 'coco_dataset'\n",
    "\n",
    "# Get the list of image files\n",
    "image_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.jpg')]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_files, [0] * len(image_files), test_size=0.1, random_state=42)\n",
    "\n",
    "print(f\"Number of training images: {len(X_train)}\")\n",
    "print(f\"Number of testing images: {len(X_test)}\")\n",
    "\n",
    "# Plot some sample images\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(4):\n",
    "    plt.subplot(1, 4, i+1)\n",
    "    plt.imshow(plt.imread(X_train[i]))\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Perform image augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    contrast_stretch_range=(0.8, 1.2)\n",
    ")\n",
    "\n",
    "# Fit and generate augmented training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Get the updated number of training and testing images\n",
    "X_train, y_train = next(train_generator)\n",
    "print(f\"Number of training images after augmentation: {len(X_train)}\")\n",
    "print(f\"Number of testing images: {len(X_test)}\")\n",
    "\n",
    "# Normalize the training data\n",
    "X_train = X_train / 255.0\n",
    "X_test = np.array([plt.imread(f) for f in X_test]) / 255.0\n",
    "\n",
    "# Build a convolutional neural network\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(80, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Show the training and testing accuracy\n",
    "print(f\"Training accuracy: {history.history['accuracy'][-1]:.2f}\")\n",
    "print(f\"Testing accuracy: {history.history['val_accuracy'][-1]:.2f}\")\n",
    "\n",
    "# Build a Faster R-CNN\n",
    "model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(80, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=model.input, outputs=predictions)\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Show the training and testing accuracy\n",
    "print(f\"Training accuracy: {history.history['accuracy'][-1]:.2f}\")\n",
    "print(f\"Testing accuracy: {history.history['val_accuracy'][-1]:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
